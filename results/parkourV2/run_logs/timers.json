{
    "name": "root",
    "gauges": {
        "ParkourBehavior.Policy.Entropy.mean": {
            "value": 1.4092867374420166,
            "min": 1.4092867374420166,
            "max": 1.4285054206848145,
            "count": 2
        },
        "ParkourBehavior.Policy.Entropy.sum": {
            "value": 14149.23828125,
            "min": 2901.29443359375,
            "max": 14149.23828125,
            "count": 2
        },
        "ParkourBehavior.Step.mean": {
            "value": 19999.0,
            "min": 9959.0,
            "max": 19999.0,
            "count": 2
        },
        "ParkourBehavior.Step.sum": {
            "value": 19999.0,
            "min": 9959.0,
            "max": 19999.0,
            "count": 2
        },
        "ParkourBehavior.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.14659526944160461,
            "min": 0.021913934499025345,
            "max": 0.14659526944160461,
            "count": 2
        },
        "ParkourBehavior.Policy.ExtrinsicValueEstimate.sum": {
            "value": 46.910484313964844,
            "min": 1.314836025238037,
            "max": 46.910484313964844,
            "count": 2
        },
        "ParkourBehavior.Environment.EpisodeLength.mean": {
            "value": 36.886792452830186,
            "min": 36.886792452830186,
            "max": 41.3125,
            "count": 2
        },
        "ParkourBehavior.Environment.EpisodeLength.sum": {
            "value": 9775.0,
            "min": 1983.0,
            "max": 9775.0,
            "count": 2
        },
        "ParkourBehavior.Environment.CumulativeReward.mean": {
            "value": 0.20754716981132076,
            "min": 0.20754716981132076,
            "max": 0.2553191489361702,
            "count": 2
        },
        "ParkourBehavior.Environment.CumulativeReward.sum": {
            "value": 55.0,
            "min": 12.0,
            "max": 55.0,
            "count": 2
        },
        "ParkourBehavior.Policy.ExtrinsicReward.mean": {
            "value": 0.20754716981132076,
            "min": 0.20754716981132076,
            "max": 0.2553191489361702,
            "count": 2
        },
        "ParkourBehavior.Policy.ExtrinsicReward.sum": {
            "value": 55.0,
            "min": 12.0,
            "max": 55.0,
            "count": 2
        },
        "ParkourBehavior.Losses.PolicyLoss.mean": {
            "value": 0.24131686634546062,
            "min": 0.24131686634546062,
            "max": 0.24900267288977573,
            "count": 2
        },
        "ParkourBehavior.Losses.PolicyLoss.sum": {
            "value": 19.78798304032777,
            "min": 3.9840427662364117,
            "max": 19.78798304032777,
            "count": 2
        },
        "ParkourBehavior.Losses.ValueLoss.mean": {
            "value": 0.055932395818657915,
            "min": 0.055932395818657915,
            "max": 0.14105274274694007,
            "count": 2
        },
        "ParkourBehavior.Losses.ValueLoss.sum": {
            "value": 4.586456457129949,
            "min": 2.256843883951041,
            "max": 4.586456457129949,
            "count": 2
        },
        "ParkourBehavior.Policy.LearningRate.mean": {
            "value": 0.00029097088105848776,
            "min": 0.00029097088105848776,
            "max": 0.00029458511430496245,
            "count": 2
        },
        "ParkourBehavior.Policy.LearningRate.sum": {
            "value": 0.023859612246795996,
            "min": 0.004713361828879399,
            "max": 0.023859612246795996,
            "count": 2
        },
        "ParkourBehavior.Policy.Epsilon.mean": {
            "value": 0.1969902926829268,
            "min": 0.1969902926829268,
            "max": 0.1981950375,
            "count": 2
        },
        "ParkourBehavior.Policy.Epsilon.sum": {
            "value": 16.153204,
            "min": 3.1711206,
            "max": 16.153204,
            "count": 2
        },
        "ParkourBehavior.Policy.Beta.mean": {
            "value": 0.0005000000000000001,
            "min": 0.0005,
            "max": 0.0005000000000000001,
            "count": 2
        },
        "ParkourBehavior.Policy.Beta.sum": {
            "value": 0.04100000000000001,
            "min": 0.008,
            "max": 0.04100000000000001,
            "count": 2
        },
        "ParkourBehavior.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 2
        },
        "ParkourBehavior.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 2
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1673724752",
        "python_version": "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\rune\\AppData\\Local\\Programs\\Python\\Python39\\Scripts\\mlagents-learn config/example_config.yaml --run-id=parkourV2 --resume",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.13.1+cpu",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1673725031"
    },
    "total": 278.58343060000004,
    "count": 1,
    "self": 0.007747100000017326,
    "children": {
        "run_training.setup": {
            "total": 0.15276780000000034,
            "count": 1,
            "self": 0.15276780000000034
        },
        "TrainerController.start_learning": {
            "total": 278.42291570000003,
            "count": 1,
            "self": 0.45503910000127235,
            "children": {
                "TrainerController._reset_env": {
                    "total": 13.7697955,
                    "count": 1,
                    "self": 13.7697955
                },
                "TrainerController.advance": {
                    "total": 264.05004249999877,
                    "count": 13465,
                    "self": 0.4564848999983724,
                    "children": {
                        "env_step": {
                            "total": 226.6079381999999,
                            "count": 13465,
                            "self": 196.77390349999723,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 29.5456114000027,
                                    "count": 13465,
                                    "self": 1.1851930000018065,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 28.360418400000892,
                                            "count": 13152,
                                            "self": 28.360418400000892
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.28842329999996963,
                                    "count": 13464,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 199.6281105999989,
                                            "count": 13464,
                                            "is_parallel": true,
                                            "self": 86.0810514999981,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.00045469999999880883,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.0002528999999977799,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00020180000000102893,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.00020180000000102893
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 113.5466044000008,
                                                    "count": 13464,
                                                    "is_parallel": true,
                                                    "self": 1.6355836000003023,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 1.3443535999992804,
                                                            "count": 13464,
                                                            "is_parallel": true,
                                                            "self": 1.3443535999992804
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 105.2141299000013,
                                                            "count": 13464,
                                                            "is_parallel": true,
                                                            "self": 105.2141299000013
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 5.352537299999929,
                                                            "count": 13464,
                                                            "is_parallel": true,
                                                            "self": 3.410773600000823,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 1.9417636999991057,
                                                                    "count": 26928,
                                                                    "is_parallel": true,
                                                                    "self": 1.9417636999991057
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 36.98561940000049,
                            "count": 13464,
                            "self": 0.50653450000015,
                            "children": {
                                "process_trajectory": {
                                    "total": 1.9975480000002932,
                                    "count": 13464,
                                    "self": 1.9975480000002932
                                },
                                "_update_policy": {
                                    "total": 34.481536900000044,
                                    "count": 108,
                                    "self": 3.7735023000002528,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 30.70803459999979,
                                            "count": 3795,
                                            "self": 30.70803459999979
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.14803860000000668,
                    "count": 1,
                    "self": 0.008105399999976726,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.13993320000002996,
                            "count": 1,
                            "self": 0.13993320000002996
                        }
                    }
                }
            }
        }
    }
}