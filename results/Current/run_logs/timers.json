{
    "name": "root",
    "gauges": {
        "ParkourBehavior.Policy.Entropy.mean": {
            "value": 1.228212594985962,
            "min": 1.114781379699707,
            "max": 1.3815574645996094,
            "count": 100
        },
        "ParkourBehavior.Policy.Entropy.sum": {
            "value": 12214.57421875,
            "min": 10020.3515625,
            "max": 16838.421875,
            "count": 100
        },
        "ParkourBehavior.Environment.EpisodeLength.mean": {
            "value": 1433.0,
            "min": 13.453757225433526,
            "max": 1433.0,
            "count": 100
        },
        "ParkourBehavior.Environment.EpisodeLength.sum": {
            "value": 1433.0,
            "min": 615.0,
            "max": 12304.0,
            "count": 100
        },
        "ParkourBehavior.Step.mean": {
            "value": 999991.0,
            "min": 9989.0,
            "max": 999991.0,
            "count": 100
        },
        "ParkourBehavior.Step.sum": {
            "value": 999991.0,
            "min": 9989.0,
            "max": 999991.0,
            "count": 100
        },
        "ParkourBehavior.Policy.ExtrinsicValue.mean": {
            "value": 56.50284957885742,
            "min": 0.9105352759361267,
            "max": 56.50284957885742,
            "count": 100
        },
        "ParkourBehavior.Policy.ExtrinsicValue.sum": {
            "value": 4463.72509765625,
            "min": 629.1798706054688,
            "max": 8238.658203125,
            "count": 100
        },
        "ParkourBehavior.Environment.CumulativeReward.mean": {
            "value": 1.0,
            "min": 0.21222410865874364,
            "max": 1.0,
            "count": 100
        },
        "ParkourBehavior.Environment.CumulativeReward.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 166.0,
            "count": 100
        },
        "ParkourBehavior.Policy.ExtrinsicReward.mean": {
            "value": 1.0,
            "min": 0.21222410865874364,
            "max": 1.0,
            "count": 100
        },
        "ParkourBehavior.Policy.ExtrinsicReward.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 166.0,
            "count": 100
        },
        "ParkourBehavior.Losses.PolicyLoss.mean": {
            "value": -56.5459720407897,
            "min": -56.5459720407897,
            "max": -1.8833169912348793,
            "count": 100
        },
        "ParkourBehavior.Losses.PolicyLoss.sum": {
            "value": -28668.807824680378,
            "min": -28799.606644871583,
            "max": -841.842695081991,
            "count": 100
        },
        "ParkourBehavior.Losses.ValueLoss.mean": {
            "value": 0.25066648436805045,
            "min": 0.03758647054216434,
            "max": 0.8821387723457295,
            "count": 100
        },
        "ParkourBehavior.Losses.ValueLoss.sum": {
            "value": 127.08790757460159,
            "min": 18.755648800540005,
            "max": 447.24435757928484,
            "count": 100
        },
        "ParkourBehavior.Losses.Q1Loss.mean": {
            "value": 0.9471117225459482,
            "min": 0.04055237266859473,
            "max": 2.563425971003636,
            "count": 100
        },
        "ParkourBehavior.Losses.Q1Loss.sum": {
            "value": 480.18564333079576,
            "min": 18.126910582861846,
            "max": 1281.712985501818,
            "count": 100
        },
        "ParkourBehavior.Losses.Q2Loss.mean": {
            "value": 0.8847460053366549,
            "min": 0.0654269008514758,
            "max": 2.557753892607194,
            "count": 100
        },
        "ParkourBehavior.Losses.Q2Loss.sum": {
            "value": 448.566224705684,
            "min": 29.245824680609687,
            "max": 1278.876946303597,
            "count": 100
        },
        "ParkourBehavior.Policy.ContinuousEntropyCoeff.mean": {
            "value": 0.3043231415457186,
            "min": 0.3043231415457186,
            "max": 0.49888203368318484,
            "count": 100
        },
        "ParkourBehavior.Policy.ContinuousEntropyCoeff.sum": {
            "value": 154.29183276367934,
            "min": 152.60657720216307,
            "max": 249.25164364079637,
            "count": 100
        },
        "ParkourBehavior.Policy.LearningRate.mean": {
            "value": 1e-05,
            "min": 1e-05,
            "max": 1.0000000000000003e-05,
            "count": 100
        },
        "ParkourBehavior.Policy.LearningRate.sum": {
            "value": 0.005070000000000001,
            "min": 0.004470000000000001,
            "max": 0.005110000000000001,
            "count": 100
        },
        "ParkourBehavior.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 100
        },
        "ParkourBehavior.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 100
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1673817318",
        "python_version": "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\rune\\AppData\\Local\\Programs\\Python\\Python39\\Scripts\\mlagents-learn Config\\config.yaml --num-areas=50",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.13.1+cu117",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1673819144"
    },
    "total": 1825.8875288,
    "count": 1,
    "self": 0.2563294000001406,
    "children": {
        "run_training.setup": {
            "total": 0.2702887999999999,
            "count": 1,
            "self": 0.2702887999999999
        },
        "TrainerController.start_learning": {
            "total": 1825.3609106,
            "count": 1,
            "self": 0.7008608999940407,
            "children": {
                "TrainerController._reset_env": {
                    "total": 4.3555589,
                    "count": 1,
                    "self": 4.3555589
                },
                "TrainerController.advance": {
                    "total": 1815.457802200006,
                    "count": 28633,
                    "self": 0.6284012000355688,
                    "children": {
                        "env_step": {
                            "total": 145.69951109997817,
                            "count": 28633,
                            "self": 58.01005970002099,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 87.2655532999647,
                                    "count": 47239,
                                    "self": 4.170905899967607,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 83.09464739999709,
                                            "count": 39728,
                                            "self": 83.09464739999709
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.4238980999924804,
                                    "count": 28633,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 7258.953128599978,
                                            "count": 47238,
                                            "is_parallel": true,
                                            "self": 6966.475947199995,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.002075500000000119,
                                                    "count": 4,
                                                    "is_parallel": true,
                                                    "self": 0.0005383999999994948,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.001537100000000624,
                                                            "count": 8,
                                                            "is_parallel": true,
                                                            "self": 0.001537100000000624
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 292.47510589998325,
                                                    "count": 47238,
                                                    "is_parallel": true,
                                                    "self": 7.172621200001004,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 13.835915500007353,
                                                            "count": 47238,
                                                            "is_parallel": true,
                                                            "self": 13.835915500007353
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 257.1493503000015,
                                                            "count": 47238,
                                                            "is_parallel": true,
                                                            "self": 257.1493503000015
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 14.317218899973398,
                                                            "count": 47238,
                                                            "is_parallel": true,
                                                            "self": 5.175019999990994,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 9.142198899982404,
                                                                    "count": 94476,
                                                                    "is_parallel": true,
                                                                    "self": 9.142198899982404
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 1669.1298898999923,
                            "count": 28633,
                            "self": 1.6124108999702003,
                            "children": {
                                "process_trajectory": {
                                    "total": 149.24494360000173,
                                    "count": 28633,
                                    "self": 148.77577830000175,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.469165299999986,
                                            "count": 2,
                                            "self": 0.469165299999986
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 1518.2725354000204,
                                    "count": 28535,
                                    "self": 0.3424630000290563,
                                    "children": {
                                        "OffPolicyTrainer._update_policy": {
                                            "total": 1517.9300723999913,
                                            "count": 28535,
                                            "self": 128.816197399992,
                                            "children": {
                                                "TorchSACOptimizer.update": {
                                                    "total": 1389.1138749999993,
                                                    "count": 49949,
                                                    "self": 1389.1138749999993
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 6.000000212225132e-07,
                    "count": 1,
                    "self": 6.000000212225132e-07
                },
                "TrainerController._save_models": {
                    "total": 4.846687999999858,
                    "count": 1,
                    "self": 4.56278479999969,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.283903200000168,
                            "count": 1,
                            "self": 0.283903200000168
                        }
                    }
                }
            }
        }
    }
}